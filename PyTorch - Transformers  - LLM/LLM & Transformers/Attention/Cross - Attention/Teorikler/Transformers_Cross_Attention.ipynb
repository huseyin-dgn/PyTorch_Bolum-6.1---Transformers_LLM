{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "989584f1",
   "metadata": {},
   "source": [
    "## ğŸ”„ Cross-Attention (Encoder-Decoder Attention) â€” DetaylÄ± AÃ§Ä±klama\n",
    "\n",
    "### 1ï¸âƒ£ AmaÃ§ ve KullanÄ±m AlanÄ±\n",
    "Cross-Attention, **transformer tabanlÄ± Encoder-Decoder modellerinde** kritik bir mekanizmadÄ±r.  \n",
    "- Encoder, girdiyi anlamlÄ± bir temsil (embedding) haline getirir.  \n",
    "- Decoder, Ã§Ä±ktÄ±yÄ± Ã¼retirken **encoderâ€™in Ã§Ä±ktÄ±sÄ±na bakarak** baÄŸlam bilgisini alÄ±r.  \n",
    "- Ã–rnek: Ã‡eviri modellerinde, decoder bir kelime Ã¼retirken hangi kaynak kelimelere dikkat edeceÄŸini Ã¶ÄŸrenir.\n",
    "\n",
    "\n",
    "### 2ï¸âƒ£ Girdi ve Ã‡Ä±kÄ±ÅŸlar\n",
    "**Girdiler:**\n",
    "- `x_dec` : Decoder inputlarÄ± â†’ Query (Q) iÃ§in kullanÄ±lÄ±r  \n",
    "- `x_enc` : Encoder outputlarÄ± â†’ Key (K) ve Value (V) iÃ§in kullanÄ±lÄ±r  \n",
    "- `mask_enc` : Encoder maskesi (padding veya attention mask)  \n",
    "\n",
    "**Ã‡Ä±ktÄ±lar:**\n",
    "- `out` : Decoder tokenâ€™larÄ±nÄ±n baÄŸlam ile zenginleÅŸtirilmiÅŸ temsili  \n",
    "- `attn` : (batch, num_heads, L_dec, L_enc) â†’ hangi decoder tokenâ€™Ä±nÄ±n hangi encoder tokenâ€™Ä±na dikkat ettiÄŸini gÃ¶sterir\n",
    "\n",
    "### 3ï¸âƒ£ AdÄ±m AdÄ±m Ä°ÅŸleyiÅŸ\n",
    "\n",
    "#### ğŸ”¹ 3.1 Query, Key, Value Hesaplama\n",
    "- Decoder tokenâ€™larÄ± `x_dec` â†’ Q  \n",
    "- Encoder tokenâ€™larÄ± `x_enc` â†’ K ve V  \n",
    "\n",
    "\\[\n",
    "Q = x_{dec} W_Q, \\quad K = x_{enc} W_K, \\quad V = x_{enc} W_V\n",
    "\\]\n",
    "\n",
    "- EÄŸer multi-head ise, her Q/K/V tensoru `(batch, num_heads, seq_len, head_dim)` ÅŸeklinde yeniden ÅŸekillendirilir.  \n",
    "\n",
    "\n",
    "#### ğŸ”¹ 3.2 Skor HesabÄ±\n",
    "- Decoder tokenâ€™larÄ±, encoder tokenâ€™larÄ±yla **benzerlik skorlarÄ±** Ã¼zerinden iliÅŸkilendirilir:\n",
    "\n",
    "\\[\n",
    "\\text{scores} = \\frac{Q K^T}{\\sqrt{d_k}}\n",
    "\\]\n",
    "\n",
    "- `d_k` â†’ head boyutu, Ã¶lÃ§ekleme faktÃ¶rÃ¼ olarak kullanÄ±lÄ±r.  \n",
    "- AmaÃ§: SkorlarÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ normalize edip softmax sonrasÄ± stabil daÄŸÄ±lÄ±m saÄŸlamak.\n",
    "\n",
    "\n",
    "\n",
    "#### ğŸ”¹ 3.3 Mask Uygulama\n",
    "- Encoder inputlarÄ±nda padding veya mask gerektiren durumlarda, skorlar mask ile `-inf` doldurularak softmax sonrasÄ± dikkate alÄ±nmaz.  \n",
    "- Bu sayede decoder, gereksiz veya geÃ§ersiz tokenâ€™lara dikkat etmez.\n",
    "\n",
    "\n",
    "#### ğŸ”¹ 3.4 Softmax ve AÄŸÄ±rlÄ±klÄ± Toplama\n",
    "- Softmax uygulanarak skorlar olasÄ±lÄ±ÄŸa Ã§evrilir: hangi decoder tokenâ€™Ä±nÄ±n hangi encoder tokenâ€™Ä±na ne kadar dikkat edeceÄŸi belirlenir.\n",
    "- ArdÄ±ndan **Value (V)** ile Ã§arpÄ±larak decoder tokenâ€™larÄ± iÃ§in **baÄŸlam (context)** oluÅŸturulur:\n",
    "\n",
    "\\[\n",
    "\\text{context} = \\text{Softmax(scores)} \\cdot V\n",
    "\\]\n",
    "\n",
    "- Bu adÄ±m, decoder tokenâ€™Ä±nÄ±n **encoder baÄŸlamÄ±nÄ± Ã¶ÄŸrenmesini** saÄŸlar.\n",
    "\n",
    "\n",
    "#### ğŸ”¹ 3.5 Head BirleÅŸtirme ve Ã‡Ä±kÄ±ÅŸ\n",
    "- Multi-head attention: TÃ¼m headâ€™ler concat edilir ve `W_O` lineer katmanÄ± ile projekte edilir.  \n",
    "- Residual baÄŸlantÄ± eklenir ve LayerNorm uygulanÄ±r:\n",
    "\n",
    "\\[\n",
    "\\text{out} = \\text{LayerNorm}(x_{dec} + \\text{Dropout}(\\text{context}))\n",
    "\\]\n",
    "\n",
    "- BÃ¶ylece hem giriÅŸ bilgisini korumuÅŸ oluruz hem de baÄŸlam ile zenginleÅŸtirilmiÅŸ bir temsil elde ederiz.\n",
    "\n",
    "\n",
    "\n",
    "### 4ï¸âƒ£ Ã–zellikler ve Avantajlar\n",
    "- **BaÄŸlam entegrasyonu:** Decoder, yalnÄ±zca kendi geÃ§miÅŸ tokenâ€™larÄ±na deÄŸil, encoderâ€™Ä±n tamamÄ±na bakabilir.  \n",
    "- **Multi-Head:** FarklÄ± â€œbakÄ±ÅŸ aÃ§Ä±larÄ±â€ ile iliÅŸkiler paralel olarak Ã¶ÄŸrenilir.  \n",
    "- **Masking:** Hem padding hem de geleceÄŸe bakma (causal) maskeleri ile esnek kullanÄ±m.  \n",
    "- **Residual + LayerNorm:** Stabil ve derinleÅŸtirilmiÅŸ Ã¶ÄŸrenme olanaÄŸÄ± saÄŸlar.\n",
    "\n",
    "\n",
    "\n",
    "### 5ï¸âƒ£ Ã–zet AkÄ±ÅŸ ÅemasÄ±\n",
    "1. Decoder input â†’ Q  \n",
    "2. Encoder output â†’ K, V  \n",
    "3. Skor hesaplama: QKáµ€ / âˆšd_k  \n",
    "4. Mask uygulama (varsa)  \n",
    "5. Softmax â†’ Attention aÄŸÄ±rlÄ±klarÄ±  \n",
    "6. AÄŸÄ±rlÄ±klÄ± toplam: attn Ã— V â†’ context  \n",
    "7. Multi-head birleÅŸtirme + Lineer Ã§Ä±kÄ±ÅŸ  \n",
    "8. Residual + LayerNorm â†’ son Ã§Ä±ktÄ±\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740533e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
