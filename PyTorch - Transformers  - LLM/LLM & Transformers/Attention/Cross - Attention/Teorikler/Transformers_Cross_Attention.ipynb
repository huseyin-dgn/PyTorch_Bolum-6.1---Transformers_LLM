{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "989584f1",
   "metadata": {},
   "source": [
    "## 🔄 Cross-Attention (Encoder-Decoder Attention) — Detaylı Açıklama\n",
    "\n",
    "### 1️⃣ Amaç ve Kullanım Alanı\n",
    "Cross-Attention, **transformer tabanlı Encoder-Decoder modellerinde** kritik bir mekanizmadır.  \n",
    "- Encoder, girdiyi anlamlı bir temsil (embedding) haline getirir.  \n",
    "- Decoder, çıktıyı üretirken **encoder’in çıktısına bakarak** bağlam bilgisini alır.  \n",
    "- Örnek: Çeviri modellerinde, decoder bir kelime üretirken hangi kaynak kelimelere dikkat edeceğini öğrenir.\n",
    "\n",
    "\n",
    "### 2️⃣ Girdi ve Çıkışlar\n",
    "**Girdiler:**\n",
    "- `x_dec` : Decoder inputları → Query (Q) için kullanılır  \n",
    "- `x_enc` : Encoder outputları → Key (K) ve Value (V) için kullanılır  \n",
    "- `mask_enc` : Encoder maskesi (padding veya attention mask)  \n",
    "\n",
    "**Çıktılar:**\n",
    "- `out` : Decoder token’larının bağlam ile zenginleştirilmiş temsili  \n",
    "- `attn` : (batch, num_heads, L_dec, L_enc) → hangi decoder token’ının hangi encoder token’ına dikkat ettiğini gösterir\n",
    "\n",
    "### 3️⃣ Adım Adım İşleyiş\n",
    "\n",
    "#### 🔹 3.1 Query, Key, Value Hesaplama\n",
    "- Decoder token’ları `x_dec` → Q  \n",
    "- Encoder token’ları `x_enc` → K ve V  \n",
    "\n",
    "\\[\n",
    "Q = x_{dec} W_Q, \\quad K = x_{enc} W_K, \\quad V = x_{enc} W_V\n",
    "\\]\n",
    "\n",
    "- Eğer multi-head ise, her Q/K/V tensoru `(batch, num_heads, seq_len, head_dim)` şeklinde yeniden şekillendirilir.  \n",
    "\n",
    "\n",
    "#### 🔹 3.2 Skor Hesabı\n",
    "- Decoder token’ları, encoder token’larıyla **benzerlik skorları** üzerinden ilişkilendirilir:\n",
    "\n",
    "\\[\n",
    "\\text{scores} = \\frac{Q K^T}{\\sqrt{d_k}}\n",
    "\\]\n",
    "\n",
    "- `d_k` → head boyutu, ölçekleme faktörü olarak kullanılır.  \n",
    "- Amaç: Skorların büyüklüğünü normalize edip softmax sonrası stabil dağılım sağlamak.\n",
    "\n",
    "\n",
    "\n",
    "#### 🔹 3.3 Mask Uygulama\n",
    "- Encoder inputlarında padding veya mask gerektiren durumlarda, skorlar mask ile `-inf` doldurularak softmax sonrası dikkate alınmaz.  \n",
    "- Bu sayede decoder, gereksiz veya geçersiz token’lara dikkat etmez.\n",
    "\n",
    "\n",
    "#### 🔹 3.4 Softmax ve Ağırlıklı Toplama\n",
    "- Softmax uygulanarak skorlar olasılığa çevrilir: hangi decoder token’ının hangi encoder token’ına ne kadar dikkat edeceği belirlenir.\n",
    "- Ardından **Value (V)** ile çarpılarak decoder token’ları için **bağlam (context)** oluşturulur:\n",
    "\n",
    "\\[\n",
    "\\text{context} = \\text{Softmax(scores)} \\cdot V\n",
    "\\]\n",
    "\n",
    "- Bu adım, decoder token’ının **encoder bağlamını öğrenmesini** sağlar.\n",
    "\n",
    "\n",
    "#### 🔹 3.5 Head Birleştirme ve Çıkış\n",
    "- Multi-head attention: Tüm head’ler concat edilir ve `W_O` lineer katmanı ile projekte edilir.  \n",
    "- Residual bağlantı eklenir ve LayerNorm uygulanır:\n",
    "\n",
    "\\[\n",
    "\\text{out} = \\text{LayerNorm}(x_{dec} + \\text{Dropout}(\\text{context}))\n",
    "\\]\n",
    "\n",
    "- Böylece hem giriş bilgisini korumuş oluruz hem de bağlam ile zenginleştirilmiş bir temsil elde ederiz.\n",
    "\n",
    "\n",
    "\n",
    "### 4️⃣ Özellikler ve Avantajlar\n",
    "- **Bağlam entegrasyonu:** Decoder, yalnızca kendi geçmiş token’larına değil, encoder’ın tamamına bakabilir.  \n",
    "- **Multi-Head:** Farklı “bakış açıları” ile ilişkiler paralel olarak öğrenilir.  \n",
    "- **Masking:** Hem padding hem de geleceğe bakma (causal) maskeleri ile esnek kullanım.  \n",
    "- **Residual + LayerNorm:** Stabil ve derinleştirilmiş öğrenme olanağı sağlar.\n",
    "\n",
    "\n",
    "\n",
    "### 5️⃣ Özet Akış Şeması\n",
    "1. Decoder input → Q  \n",
    "2. Encoder output → K, V  \n",
    "3. Skor hesaplama: QKᵀ / √d_k  \n",
    "4. Mask uygulama (varsa)  \n",
    "5. Softmax → Attention ağırlıkları  \n",
    "6. Ağırlıklı toplam: attn × V → context  \n",
    "7. Multi-head birleştirme + Lineer çıkış  \n",
    "8. Residual + LayerNorm → son çıktı\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740533e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
