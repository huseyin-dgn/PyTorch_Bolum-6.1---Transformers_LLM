{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a85c64",
   "metadata": {},
   "source": [
    "# 🧮 Self-Attention Hesaplama Adımları (örnek matrislerle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ab1b7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Self-Attention, bir dizideki her kelimenin **diğer kelimelerle ne kadar ilişkili olduğunu** öğrenmesini sağlar.  \n",
    "Bu bölümde, **adım adım matematiksel olarak** nasıl çalıştığını görelim 👇\n",
    "\n",
    "## 🔹 1. Girdi Temsilleri (Embeddings)\n",
    "\n",
    "Cümlemiz:\n",
    "> “Ben okula gidiyorum”\n",
    "\n",
    "Her kelime, embedding katmanı ile vektöre dönüştürülür:\n",
    "\n",
    "| Kelime | Vektör (örnek) |\n",
    "|---------|----------------|\n",
    "| Ben | [0.2, 0.7, 0.1] |\n",
    "| Okula | [0.9, 0.1, 0.3] |\n",
    "| Gidiyorum | [0.4, 0.5, 0.8] |\n",
    "\n",
    "Bu vektörler birleşerek bir matris oluşturur:\n",
    "\n",
    "\\[\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "0.2 & 0.7 & 0.1 \\\\\n",
    "0.9 & 0.1 & 0.3 \\\\\n",
    "0.4 & 0.5 & 0.8\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "## 🔹 2. Q, K, V Matrislerinin Hesaplanması\n",
    "\n",
    "Her kelime için **üç ayrı temsil** hesaplanır:\n",
    "\n",
    "- **Q (Query)** → ne arıyoruz  \n",
    "- **K (Key)** → hangi bilgiyi temsil ediyoruz  \n",
    "- **V (Value)** → hangi bilgiyi aktaracağız  \n",
    "\n",
    "Bu üçü, öğrenilebilir ağırlık matrisleriyle elde edilir:\n",
    "\n",
    "\\[\n",
    "Q = XW_Q,\\quad K = XW_K,\\quad V = XW_V\n",
    "\\]\n",
    "\n",
    "Burada \\( W_Q, W_K, W_V \\) öğrenilen parametrelerdir.\n",
    "\n",
    "\n",
    "\n",
    "## 🔹 3. Dikkat Skorlarının Hesaplanması\n",
    "\n",
    "Her kelimenin diğer kelimelere olan dikkatini bulmak için **Q ile K** çarpılır:\n",
    "\n",
    "\\[\n",
    "\\text{Skorlar} = QK^T\n",
    "\\]\n",
    "\n",
    "Bu bize, kelimeler arası ilişki skorlarını verir.\n",
    "\n",
    "Örnek (3 kelimelik cümle için):\n",
    "\\[\n",
    "QK^T =\n",
    "\\begin{bmatrix}\n",
    "4 & 2 & 1 \\\\\n",
    "2 & 3 & 0 \\\\\n",
    "1 & 0 & 2\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "## 🔹 4. Skorların Ölçeklenmesi\n",
    "\n",
    "Skorlar çok büyük olabilir, bu yüzden stabilize etmek için boyut köküne bölünür:\n",
    "\n",
    "\\[\n",
    "\\text{Scaled Scores} = \\frac{QK^T}{\\sqrt{d_k}}\n",
    "\\]\n",
    "\n",
    "Eğer \\( d_k = 64 \\) ise, √64 = 8 olur.\n",
    "\n",
    "\n",
    "## 🔹 5. Softmax Uygulama\n",
    "\n",
    "Her satır (kelime) için softmax uygulanır, böylece skorlar olasılık haline gelir:\n",
    "\n",
    "\\[\n",
    "\\text{Attention Weights} = softmax\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)\n",
    "\\]\n",
    "\n",
    "Örnek:\n",
    "\\[\n",
    "\\text{Attention Weights} =\n",
    "\\begin{bmatrix}\n",
    "0.7 & 0.2 & 0.1 \\\\\n",
    "0.4 & 0.5 & 0.1 \\\\\n",
    "0.2 & 0.1 & 0.7\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "## 🔹 6. Değerlerin (V) Ağırlıklı Ortalaması\n",
    "\n",
    "Son olarak bu ağırlıklar, **V** matrisiyle çarpılır:\n",
    "\n",
    "\\[\n",
    "\\text{Output} = \\text{Attention Weights} \\times V\n",
    "\\]\n",
    "\n",
    "Bu işlem, her kelimenin diğerlerinden topladığı bilgiyi temsil eder.\n",
    "\n",
    "\n",
    "## 🔹 7. Multi-Head Attention (Opsiyonel)\n",
    "\n",
    "Birden fazla “head” kullanılarak bu işlem paralel yapılır:\n",
    "\n",
    "\\[\n",
    "\\text{MultiHead}(Q, K, V) = Concat(head_1, head_2, ..., head_h)W_O\n",
    "\\]\n",
    "\n",
    "Her head, farklı ilişkileri (örneğin anlam, zaman, yön, nesne) öğrenir.\n",
    "\n",
    "\n",
    "\n",
    "## 🧠 Özet\n",
    "\n",
    "| Adım | İşlem | Amaç |\n",
    "|------|--------|-------|\n",
    "| 1 | Embedding | Girdiyi vektörlere çevirir |\n",
    "| 2 | Q, K, V | Her kelime için 3 farklı temsil üretir |\n",
    "| 3 | Q × Kᵀ | Dikkat skorlarını hesaplar |\n",
    "| 4 | Ölçekleme | Skorları normalize eder |\n",
    "| 5 | Softmax | Olasılık dağılımı oluşturur |\n",
    "| 6 | V ile çarp | Bilgiyi ağırlıklı topla |\n",
    "| 7 | Multi-Head | Farklı dikkat türlerini öğren |\n",
    "\n",
    "\n",
    "## 📚 Sonuç\n",
    "\n",
    "- **Self-Attention**, her kelimenin tüm cümleye aynı anda bakmasını sağlar.  \n",
    "- **Uzun bağımlılık sorunlarını çözer.**  \n",
    "- **Transformer’ın kalbidir** — Encoder ve Decoder bloklarının temel yapı taşıdır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696875ea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
