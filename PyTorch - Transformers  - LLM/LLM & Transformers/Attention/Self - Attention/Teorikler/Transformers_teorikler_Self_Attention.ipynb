{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a85c64",
   "metadata": {},
   "source": [
    "# ğŸ§® Self-Attention Hesaplama AdÄ±mlarÄ± (Ã¶rnek matrislerle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ab1b7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Self-Attention, bir dizideki her kelimenin **diÄŸer kelimelerle ne kadar iliÅŸkili olduÄŸunu** Ã¶ÄŸrenmesini saÄŸlar.  \n",
    "Bu bÃ¶lÃ¼mde, **adÄ±m adÄ±m matematiksel olarak** nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶relim ğŸ‘‡\n",
    "\n",
    "## ğŸ”¹ 1. Girdi Temsilleri (Embeddings)\n",
    "\n",
    "CÃ¼mlemiz:\n",
    "> â€œBen okula gidiyorumâ€\n",
    "\n",
    "Her kelime, embedding katmanÄ± ile vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r:\n",
    "\n",
    "| Kelime | VektÃ¶r (Ã¶rnek) |\n",
    "|---------|----------------|\n",
    "| Ben | [0.2, 0.7, 0.1] |\n",
    "| Okula | [0.9, 0.1, 0.3] |\n",
    "| Gidiyorum | [0.4, 0.5, 0.8] |\n",
    "\n",
    "Bu vektÃ¶rler birleÅŸerek bir matris oluÅŸturur:\n",
    "\n",
    "\\[\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "0.2 & 0.7 & 0.1 \\\\\n",
    "0.9 & 0.1 & 0.3 \\\\\n",
    "0.4 & 0.5 & 0.8\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ”¹ 2. Q, K, V Matrislerinin HesaplanmasÄ±\n",
    "\n",
    "Her kelime iÃ§in **Ã¼Ã§ ayrÄ± temsil** hesaplanÄ±r:\n",
    "\n",
    "- **Q (Query)** â†’ ne arÄ±yoruz  \n",
    "- **K (Key)** â†’ hangi bilgiyi temsil ediyoruz  \n",
    "- **V (Value)** â†’ hangi bilgiyi aktaracaÄŸÄ±z  \n",
    "\n",
    "Bu Ã¼Ã§Ã¼, Ã¶ÄŸrenilebilir aÄŸÄ±rlÄ±k matrisleriyle elde edilir:\n",
    "\n",
    "\\[\n",
    "Q = XW_Q,\\quad K = XW_K,\\quad V = XW_V\n",
    "\\]\n",
    "\n",
    "Burada \\( W_Q, W_K, W_V \\) Ã¶ÄŸrenilen parametrelerdir.\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ”¹ 3. Dikkat SkorlarÄ±nÄ±n HesaplanmasÄ±\n",
    "\n",
    "Her kelimenin diÄŸer kelimelere olan dikkatini bulmak iÃ§in **Q ile K** Ã§arpÄ±lÄ±r:\n",
    "\n",
    "\\[\n",
    "\\text{Skorlar} = QK^T\n",
    "\\]\n",
    "\n",
    "Bu bize, kelimeler arasÄ± iliÅŸki skorlarÄ±nÄ± verir.\n",
    "\n",
    "Ã–rnek (3 kelimelik cÃ¼mle iÃ§in):\n",
    "\\[\n",
    "QK^T =\n",
    "\\begin{bmatrix}\n",
    "4 & 2 & 1 \\\\\n",
    "2 & 3 & 0 \\\\\n",
    "1 & 0 & 2\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ”¹ 4. SkorlarÄ±n Ã–lÃ§eklenmesi\n",
    "\n",
    "Skorlar Ã§ok bÃ¼yÃ¼k olabilir, bu yÃ¼zden stabilize etmek iÃ§in boyut kÃ¶kÃ¼ne bÃ¶lÃ¼nÃ¼r:\n",
    "\n",
    "\\[\n",
    "\\text{Scaled Scores} = \\frac{QK^T}{\\sqrt{d_k}}\n",
    "\\]\n",
    "\n",
    "EÄŸer \\( d_k = 64 \\) ise, âˆš64 = 8 olur.\n",
    "\n",
    "\n",
    "## ğŸ”¹ 5. Softmax Uygulama\n",
    "\n",
    "Her satÄ±r (kelime) iÃ§in softmax uygulanÄ±r, bÃ¶ylece skorlar olasÄ±lÄ±k haline gelir:\n",
    "\n",
    "\\[\n",
    "\\text{Attention Weights} = softmax\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)\n",
    "\\]\n",
    "\n",
    "Ã–rnek:\n",
    "\\[\n",
    "\\text{Attention Weights} =\n",
    "\\begin{bmatrix}\n",
    "0.7 & 0.2 & 0.1 \\\\\n",
    "0.4 & 0.5 & 0.1 \\\\\n",
    "0.2 & 0.1 & 0.7\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ”¹ 6. DeÄŸerlerin (V) AÄŸÄ±rlÄ±klÄ± OrtalamasÄ±\n",
    "\n",
    "Son olarak bu aÄŸÄ±rlÄ±klar, **V** matrisiyle Ã§arpÄ±lÄ±r:\n",
    "\n",
    "\\[\n",
    "\\text{Output} = \\text{Attention Weights} \\times V\n",
    "\\]\n",
    "\n",
    "Bu iÅŸlem, her kelimenin diÄŸerlerinden topladÄ±ÄŸÄ± bilgiyi temsil eder.\n",
    "\n",
    "\n",
    "## ğŸ”¹ 7. Multi-Head Attention (Opsiyonel)\n",
    "\n",
    "Birden fazla â€œheadâ€ kullanÄ±larak bu iÅŸlem paralel yapÄ±lÄ±r:\n",
    "\n",
    "\\[\n",
    "\\text{MultiHead}(Q, K, V) = Concat(head_1, head_2, ..., head_h)W_O\n",
    "\\]\n",
    "\n",
    "Her head, farklÄ± iliÅŸkileri (Ã¶rneÄŸin anlam, zaman, yÃ¶n, nesne) Ã¶ÄŸrenir.\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ§  Ã–zet\n",
    "\n",
    "| AdÄ±m | Ä°ÅŸlem | AmaÃ§ |\n",
    "|------|--------|-------|\n",
    "| 1 | Embedding | Girdiyi vektÃ¶rlere Ã§evirir |\n",
    "| 2 | Q, K, V | Her kelime iÃ§in 3 farklÄ± temsil Ã¼retir |\n",
    "| 3 | Q Ã— Káµ€ | Dikkat skorlarÄ±nÄ± hesaplar |\n",
    "| 4 | Ã–lÃ§ekleme | SkorlarÄ± normalize eder |\n",
    "| 5 | Softmax | OlasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± oluÅŸturur |\n",
    "| 6 | V ile Ã§arp | Bilgiyi aÄŸÄ±rlÄ±klÄ± topla |\n",
    "| 7 | Multi-Head | FarklÄ± dikkat tÃ¼rlerini Ã¶ÄŸren |\n",
    "\n",
    "\n",
    "## ğŸ“š SonuÃ§\n",
    "\n",
    "- **Self-Attention**, her kelimenin tÃ¼m cÃ¼mleye aynÄ± anda bakmasÄ±nÄ± saÄŸlar.  \n",
    "- **Uzun baÄŸÄ±mlÄ±lÄ±k sorunlarÄ±nÄ± Ã§Ã¶zer.**  \n",
    "- **Transformerâ€™Ä±n kalbidir** â€” Encoder ve Decoder bloklarÄ±nÄ±n temel yapÄ± taÅŸÄ±dÄ±r.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696875ea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
