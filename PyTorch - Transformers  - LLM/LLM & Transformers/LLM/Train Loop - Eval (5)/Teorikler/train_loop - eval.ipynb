{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a91386",
   "metadata": {},
   "source": [
    "# 🔹 LLM Train Loop Teorisi\n",
    "\n",
    "LLM'lerde **train loop**, modelin veriyi öğrenmesini sağlayan çekirdek mekanizmadır. Burada **compile**, **metric** veya **validation** kısmına girmeden sadece **forward, loss ve backward** adımlarını ele alıyoruz.\n",
    "\n",
    "\n",
    "## 1️⃣ Veri Hazırlığı ve Batch İşleme\n",
    "- Veriler **mini-batch** hâlinde işlenir:\n",
    "  - `input_ids` → Encoder/Decoder girişleri\n",
    "  - `target_ids` → Öğrenilecek hedef token dizileri\n",
    "- **Amaç:** GPU hafızasını korumak ve öğrenmeyi stabil hâle getirmek.\n",
    "\n",
    "> Mini-batch, hem hesaplama verimliliği sağlar hem de gradyanların daha stabil olmasına yardımcı olur.\n",
    "\n",
    "\n",
    "## 2️⃣ Forward Pass\n",
    "- Model, ağırlıklar üzerinden veri geçirir ve **tahminler (logits)** üretir.\n",
    "- **Decoder** için genellikle **teacher forcing** uygulanır:\n",
    "  - Decoder’a bir adım kaydırılmış hedef tokenlar verilir.\n",
    "  - Hataların birikmesi engellenir, öğrenme hızlanır.\n",
    "- Çıkış boyutu: `[batch_size, seq_len, vocab_size]`\n",
    "\n",
    "\n",
    "## 3️⃣ Loss Hesaplama\n",
    "- Tahminler ile gerçek hedefler arasındaki fark ölçülür.\n",
    "- Genellikle **CrossEntropyLoss** kullanılır:\n",
    "  - Padding tokenlar loss hesabına dahil edilmez (`ignore_index=PAD_TOKEN`)\n",
    "- Tensor boyutları reshape edilir: `[B*T, V]` ve `[B*T]`\n",
    "\n",
    "> Model her token için doğru kelimeyi tahmin etmeye çalışır. Loss, token’ların ortalaması olarak hesaplanır.\n",
    "\n",
    "\n",
    "## 4️⃣ Backward Pass ve Optimize\n",
    "- `loss.backward()` → Gradyanlar hesaplanır (chain rule)\n",
    "- **Gradient clipping** → Çok derin ağlarda gradyan patlamasını önler\n",
    "- `optimizer.step()` → Model ağırlıkları güncellenir\n",
    "\n",
    "> Forward’da hesaplanan hatayı geriye yayarak model daha doğru tahminler yapmayı öğrenir.\n",
    "\n",
    "\n",
    "## 5️⃣ Epoch Döngüsü\n",
    "- Her **epoch**, tüm veri üzerinden bir geçiştir.\n",
    "- Genellikle epoch sonunda:\n",
    "  - Ortalama loss hesaplanır\n",
    "  - Modelin öğrenme durumu gözlemlenir\n",
    "\n",
    "> Validation veya metric hesaplama burada işlenmez; sadece **train loop çekirdeği** odaklanılır.\n",
    "\n",
    "\n",
    "\n",
    "## 🔑 Özet Mantık\n",
    "1. **Batch al** → Veri küçük parçalara bölünür  \n",
    "2. **Forward** → Model tahmin yapar (teacher forcing)  \n",
    "3. **Loss** → Tahmin ile gerçek hedef karşılaştırılır  \n",
    "4. **Backward** → Gradyanlar hesaplanır  \n",
    "5. **Optimize** → Ağırlıklar güncellenir  \n",
    "\n",
    "> Bu 5 adım, tüm LLM train loop’larının temelini oluşturur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e5140e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046fd53b",
   "metadata": {},
   "source": [
    "# LLM Train Loop:\n",
    "```bash\n",
    "\n",
    "Start Epoch\n",
    "   │\n",
    "   ▼\n",
    "Load Mini-Batch\n",
    "   │\n",
    "   ▼\n",
    "Move input_ids & target_ids to Device\n",
    "   │\n",
    "   ▼\n",
    "Forward Pass (model(input_ids, target_ids))\n",
    "   │\n",
    "   ▼\n",
    "Compute Loss (CrossEntropyLoss)\n",
    "   │\n",
    "   ▼\n",
    "Backward Pass (loss.backward())\n",
    "   │\n",
    "   ▼\n",
    "Gradient Clipping (optional)\n",
    "   │\n",
    "   ▼\n",
    "Optimizer Step (update model weights)\n",
    "   │\n",
    "   ▼\n",
    "Accumulate total_loss\n",
    "   │\n",
    "   ▼\n",
    "More Batches? ── Yes ──▶ Back to Load Mini-Batch\n",
    "      │\n",
    "      No\n",
    "      │\n",
    "      ▼\n",
    "Compute Average Loss for Epoch\n",
    "      │\n",
    "      ▼\n",
    "More Epochs? ── Yes ──▶ Back to Load Mini-Batch\n",
    "      │\n",
    "      No\n",
    "      │\n",
    "      ▼\n",
    "End Training Loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d603eb4b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
